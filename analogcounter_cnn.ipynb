{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "analogcounter_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rochefort8/AnalogCounter-NN/blob/master/analogcounter_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JneQLRfWJ1G3",
        "colab_type": "text"
      },
      "source": [
        "## 新しいセクション"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fECZK-7me4_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pk8Yweix8KZ4",
        "colab_type": "code",
        "outputId": "3d47fae6-39bb-4091-90ba-06efc9ab0bef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "!rm -rf /var/test\n",
        "!rm -rf /var/input\n",
        "\n",
        "!tar zxpf  \"/content/drive/My Drive/AC/input.tar.gz\" -C /var \n",
        "!tar zxpf  \"/content/drive/My Drive/AC/test.tar.gz\" -C /var \n",
        "#!tar zxpf /var/input.tar.gz -C /var\n",
        "#!tar zxpf /var/test.tar.gz -C /var"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9qs4lPyFpnv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!rm /var/input.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIwHNLGIJ-ql",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''Trains a simple convnet on the MNIST dataset.\n",
        "Gets to 99.25% test accuracy after 12 epochs\n",
        "(there is still a lot of margin for parameter tuning).\n",
        "16 seconds per epoch on a GRID K520 GPU.\n",
        "'''\n",
        "\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "from PIL import Image\n",
        "from io import BytesIO \n",
        "\n",
        "import cv2 as cv\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cuupkHfYOwM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# the data, split between train and test sets\n",
        "#(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# print(type(y_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LdKxeQ9ypW3",
        "colab_type": "code",
        "outputId": "75ed0205-499c-405a-8f38-79079b56fa10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        }
      },
      "source": [
        "X=[]\n",
        "Y=[]\n",
        "\n",
        "for number in range (10):  \n",
        "  path = \"/var/input/\" + str(number) + \"/\"\n",
        "  files = os.listdir(path)\n",
        "  print(number)\n",
        "  for file in files:\n",
        "      img = np.asarray(cv.imread(path + file,0))\n",
        "\n",
        "#      threshold = 66\n",
        "#      ret,img = cv.threshold(img,threshold,255,cv.THRESH_TOZERO)\n",
        "#      threshold = 100\n",
        "#      ret,img = cv.threshold(img,threshold,255,cv.THRESH_BINARY)\n",
        "\n",
        "      X.append(img)\n",
        "      Y.append(number)\n",
        "\n",
        "np.random.seed(1)\n",
        "np.random.shuffle(X)\n",
        "np.random.seed(1)\n",
        "np.random.shuffle(Y)\n",
        "\n",
        "#x_train = np.array(X)\n",
        "#y_train = np.array(Y)\n",
        "_x_train, _x_test, _y_train, _y_test =train_test_split(X, Y, test_size=0.33, random_state=111)\n",
        "x_train = np.array(_x_train)\n",
        "x_test = np.array(_x_test)\n",
        "y_train = np.array(_y_train)\n",
        "y_test = np.array(_y_test)\n",
        "\n",
        "idx = 704\n",
        "plt.imshow(x_train[idx])\n",
        "print(y_train[idx])\n",
        "\n",
        "#(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "XX=[]\n",
        "YY=[]\n",
        "\n",
        "for number in range (10):  \n",
        "  path = \"/var/test/\" + \"{:02d}\".format(number) + \"/\"\n",
        "  files = os.listdir(path)\n",
        "  del XX[:]\n",
        "  del YY[:]\n",
        "  for file in files:\n",
        "#      im2 = Image.open(path + file)\n",
        "      img = np.asarray(cv.imread(path + file,0))\n",
        "      threshold = 66\n",
        "      ret,img = cv.threshold(img,threshold,255,cv.THRESH_TOZERO)\n",
        "#      threshold = 100\n",
        "#      ret,img = cv.threshold(img,threshold,255,cv.THRESH_BINARY)\n",
        "      XX.append(img)\n",
        "      YY.append(number)\n",
        "\n",
        "np.random.seed(1)\n",
        "np.random.shuffle(XX)\n",
        "np.random.seed(1)\n",
        "np.random.shuffle(YY)\n",
        "\n",
        "#x_test = np.array(XX)\n",
        "#y_test = np.array(YY)\n",
        "#(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ve0-0z2HcSpv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-v6qXV3eTQv",
        "colab_type": "code",
        "outputId": "2bef50cc-cc1d-4be7-d9db-bfb7a174014a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "model.save('/var/tmp/ac')\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "print(score)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (7530, 28, 28, 1)\n",
            "7530 train samples\n",
            "3710 test samples\n",
            "Train on 7530 samples, validate on 3710 samples\n",
            "Epoch 1/12\n",
            "7530/7530 [==============================] - 3s 376us/step - loss: 1.0437 - acc: 0.6645 - val_loss: 0.3345 - val_acc: 0.9102\n",
            "Epoch 2/12\n",
            "7530/7530 [==============================] - 1s 170us/step - loss: 0.2621 - acc: 0.9244 - val_loss: 0.1099 - val_acc: 0.9730\n",
            "Epoch 3/12\n",
            "7530/7530 [==============================] - 1s 178us/step - loss: 0.1358 - acc: 0.9633 - val_loss: 0.0851 - val_acc: 0.9765\n",
            "Epoch 4/12\n",
            "7530/7530 [==============================] - 1s 172us/step - loss: 0.0906 - acc: 0.9744 - val_loss: 0.0597 - val_acc: 0.9841\n",
            "Epoch 5/12\n",
            "7530/7530 [==============================] - 1s 168us/step - loss: 0.0644 - acc: 0.9806 - val_loss: 0.0406 - val_acc: 0.9889\n",
            "Epoch 6/12\n",
            "7530/7530 [==============================] - 1s 175us/step - loss: 0.0561 - acc: 0.9835 - val_loss: 0.0405 - val_acc: 0.9889\n",
            "Epoch 7/12\n",
            "7530/7530 [==============================] - 1s 174us/step - loss: 0.0399 - acc: 0.9887 - val_loss: 0.0312 - val_acc: 0.9914\n",
            "Epoch 8/12\n",
            "7530/7530 [==============================] - 1s 171us/step - loss: 0.0317 - acc: 0.9914 - val_loss: 0.0264 - val_acc: 0.9927\n",
            "Epoch 9/12\n",
            "7530/7530 [==============================] - 1s 171us/step - loss: 0.0291 - acc: 0.9908 - val_loss: 0.0245 - val_acc: 0.9935\n",
            "Epoch 10/12\n",
            "7530/7530 [==============================] - 1s 177us/step - loss: 0.0273 - acc: 0.9906 - val_loss: 0.0250 - val_acc: 0.9927\n",
            "Epoch 11/12\n",
            "7530/7530 [==============================] - 1s 178us/step - loss: 0.0221 - acc: 0.9938 - val_loss: 0.0222 - val_acc: 0.9946\n",
            "Epoch 12/12\n",
            "7530/7530 [==============================] - 1s 171us/step - loss: 0.0182 - acc: 0.9946 - val_loss: 0.0205 - val_acc: 0.9949\n",
            "Test loss: 0.020486927607973455\n",
            "Test accuracy: 0.994878706199461\n",
            "[0.020486927607973455, 0.994878706199461]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPQDE6faWKgb",
        "colab_type": "code",
        "outputId": "17ae44af-2e65-463c-88bc-b51da7fc55d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 996
        }
      },
      "source": [
        "#(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "XX=[]\n",
        "YY=[]\n",
        "\n",
        "for number in range (10):  \n",
        "  path = \"/var/test/\" + \"{:02d}\".format(number) + \"/\"\n",
        "  files = os.listdir(path)\n",
        "  del XX[:]\n",
        "  del YY[:]\n",
        "\n",
        "  for file in files:\n",
        "#      im2 = Image.open(path + file)\n",
        "\n",
        "      img = np.asarray(cv.imread(path + file,0))\n",
        "      threshold = 66\n",
        "      ret,img = cv.threshold(img,threshold,255,cv.THRESH_TOZERO)\n",
        "#      threshold = 100\n",
        "#      ret,img = cv.threshold(img,threshold,255,cv.THRESH_TOZERO)\n",
        "\n",
        "      XX.append(img)\n",
        "      YY.append(number)\n",
        "\n",
        "  x_data = np.array(XX) \n",
        "  y_data = np.array(YY)\n",
        "\n",
        "  if K.image_data_format() == 'channels_first':\n",
        "    x_data = x_data.reshape(x_data.shape[0], 1, img_rows, img_cols)\n",
        "  else:\n",
        "    x_data = x_data.reshape(x_data.shape[0], img_rows, img_cols, 1)\n",
        "\n",
        "  x_data = x_data.astype('float32')\n",
        "  x_data /= 255\n",
        "  y_data = keras.utils.to_categorical(y_data, num_classes)\n",
        "  score = model.evaluate(x_data, y_data, verbose=0)\n",
        "  print('Number :' +str(number))\n",
        "  print('Test loss:', score[0])\n",
        "  print('Test accuracy:', score[1])\n",
        "  expect = model.predict_classes(x_data,batch_size=5)\n",
        "  print(expect)\n",
        "\n",
        "del XX[:]\n",
        "del YY[:]\n",
        "\n",
        "for number in range (10):  \n",
        "  path = \"/var/test/\" + \"{:02d}\".format(number) + \"/\"\n",
        "  files = os.listdir(path)\n",
        "  for file in files:\n",
        "      im2 = Image.open(path + file)\n",
        "      img = np.asarray(cv.imread(path + file,0).reshape(28,28))\n",
        "\n",
        "      threshold = 66\n",
        "      ret,img = cv.threshold(img,threshold,255,cv.THRESH_TOZERO)\n",
        "#      threshold = 100\n",
        "#      ret,img = cv.threshold(img,threshold,255,cv.THRESH_TOZERO)\n",
        "#      ret,img = cv.threshold(img,threshold,255,cv.THRESH_BINARY)\n",
        "      XX.append(img)\n",
        "      YY.append(number)\n",
        "\n",
        "np.random.seed(1)\n",
        "np.random.shuffle(XX)\n",
        "np.random.seed(1)\n",
        "np.random.shuffle(YY)\n",
        "\n",
        "plt.imshow(XX[0])\n",
        "\n",
        "x_data = np.array(XX)\n",
        "y_data = np.array(YY)\n",
        "\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_data = x_data.reshape(x_data.shape[0], 1, img_rows, img_cols)\n",
        "else:\n",
        "    x_data = x_data.reshape(x_data.shape[0], img_rows, img_cols, 1)\n",
        "\n",
        "x_data = x_data.astype('float32')\n",
        "x_data /= 255\n",
        "y_data = keras.utils.to_categorical(y_data, num_classes)\n",
        "score = model.evaluate(x_data, y_data, verbose=0)\n",
        "print('=== Total ====')\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number :0\n",
            "Test loss: 0.07764292508363724\n",
            "Test accuracy: 1.0\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Number :1\n",
            "Test loss: 0.0038528505247086287\n",
            "Test accuracy: 1.0\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "Number :2\n",
            "Test loss: 0.0786777213215828\n",
            "Test accuracy: 0.9599999785423279\n",
            "[2 2 2 2 2 2 2 2 2 2 2 2 7 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Number :3\n",
            "Test loss: 0.06040415167808533\n",
            "Test accuracy: 0.9599999785423279\n",
            "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 3 3 3 3 3 3 3]\n",
            "Number :4\n",
            "Test loss: 0.025700245052576065\n",
            "Test accuracy: 1.0\n",
            "[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
            "Number :5\n",
            "Test loss: 0.01194782741367817\n",
            "Test accuracy: 1.0\n",
            "[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
            "Number :6\n",
            "Test loss: 0.1464880406856537\n",
            "Test accuracy: 1.0\n",
            "[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
            "Number :7\n",
            "Test loss: 0.04290410503745079\n",
            "Test accuracy: 1.0\n",
            "[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
            "Number :8\n",
            "Test loss: 0.004644074477255344\n",
            "Test accuracy: 1.0\n",
            "[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
            "Number :9\n",
            "Test loss: 0.0023102641571313143\n",
            "Test accuracy: 1.0\n",
            "[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
            "=== Total ====\n",
            "Test loss: 0.04545722153782845\n",
            "Test accuracy: 0.992\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngiDsQBCEHQiCsANBEHYgiP8Hd1tSrYQ9Xk8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwkQls_uAbhE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}