{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "analogcounter_resnet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rochefort8/AnalogCounter-NN/blob/master/analogcounter_resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JneQLRfWJ1G3",
        "colab_type": "text"
      },
      "source": [
        "## 新しいセクション"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fECZK-7me4_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pk8Yweix8KZ4",
        "colab_type": "code",
        "outputId": "404809d3-421e-4468-e9a9-98273e653874",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "!rm -rf /var/test\n",
        "!rm -rf /var/input\n",
        "\n",
        "!tar zxpf  \"/content/drive/My Drive/AC/input.tar.gz\" -C /var \n",
        "!tar zxpf  \"/content/drive/My Drive/AC/test.tar.gz\" -C /var \n",
        "#!tar zxpf /var/input.tar.gz -C /var\n",
        "#!tar zxpf /var/test.tar.gz -C /var"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9qs4lPyFpnv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!rm /var/input.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIwHNLGIJ-ql",
        "colab_type": "code",
        "outputId": "dc18dc79-b641-4a40-af35-ecdf9697f458",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        }
      },
      "source": [
        "'''Trains a simple convnet on the MNIST dataset.\n",
        "Gets to 99.25% test accuracy after 12 epochs\n",
        "(there is still a lot of margin for parameter tuning).\n",
        "16 seconds per epoch on a GRID K520 GPU.\n",
        "'''\n",
        "\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "from PIL import Image\n",
        "from io import BytesIO \n",
        "\n",
        "import cv2 as cv\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WM1ogEZIW64",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JjVfDpz_C_Ut",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Input, add\n",
        "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras import Model\n",
        "from keras import backend as K\n",
        "\n",
        "def rescell(data, filters, kernel_size, option=False):\n",
        "    strides=(1,1)\n",
        "    if option:\n",
        "        strides=(2,2)\n",
        "    x=Conv2D(filters=filters,kernel_size=kernel_size,strides=strides,padding=\"same\")(data)\n",
        "    x=BatchNormalization()(x)\n",
        "    x=Activation('relu')(x)\n",
        "    \n",
        "    data=Conv2D(filters=int(x.shape[3]), kernel_size=(1,1), strides=strides, padding=\"same\")(data)\n",
        "    x=Conv2D(filters=filters,kernel_size=kernel_size,strides=(1,1),padding=\"same\")(x)\n",
        "    x=BatchNormalization()(x)\n",
        "    x=add([x,data])\n",
        "    x=Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def ResNet(img_rows, img_cols, img_channels, x_train):\n",
        "\tinput=Input(shape=(img_rows,img_cols,img_channels))\n",
        "\tx=Conv2D(32,(7,7), padding=\"same\", input_shape=x_train.shape[1:],activation=\"relu\")(input)\n",
        "\tx=MaxPooling2D(pool_size=(2,2))(x)\n",
        "\n",
        "\tx=rescell(x,64,(3,3))\n",
        "\tx=rescell(x,64,(3,3))\n",
        "\tx=rescell(x,64,(3,3))\n",
        "\n",
        "\tx=rescell(x,128,(3,3),True)\n",
        "\n",
        "\tx=rescell(x,128,(3,3))\n",
        "\tx=rescell(x,128,(3,3))\n",
        "\tx=rescell(x,128,(3,3))\n",
        "\n",
        "\tx=rescell(x,256,(3,3),True)\n",
        "\n",
        "\tx=rescell(x,256,(3,3))\n",
        "\tx=rescell(x,256,(3,3))\n",
        "\tx=rescell(x,256,(3,3))\n",
        "\tx=rescell(x,256,(3,3))\n",
        "\tx=rescell(x,256,(3,3))\n",
        "\n",
        "\tx=rescell(x,512,(3,3),True)\n",
        "\n",
        "\tx=rescell(x,512,(3,3))\n",
        "\tx=rescell(x,512,(3,3))\n",
        "\n",
        "\tx=AveragePooling2D(pool_size=(int(x.shape[1]),int(x.shape[2])),strides=(2,2))(x)\n",
        "\n",
        "\tx=Flatten()(x)\n",
        "\tx=Dense(units=10,kernel_initializer=\"he_normal\",activation=\"softmax\")(x)\n",
        "\tmodel=Model(inputs=input,outputs=[x])\n",
        "\treturn model\n",
        "\n",
        "  # 入力画像の次元とチャンネル\n",
        "img_rows, img_cols, img_channels = 28, 28, 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BKPONmf2C9IG",
        "colab": {}
      },
      "source": [
        "\n",
        "# the data, split between train and test sets\n",
        "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# print(type(y_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LdKxeQ9ypW3",
        "colab_type": "code",
        "outputId": "0738d5b4-2e00-428e-f466-5b047534f0f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        }
      },
      "source": [
        "X=[]\n",
        "Y=[]\n",
        "\n",
        "for number in range (10):  \n",
        "  path = \"/var/input/\" + str(number) + \"/\"\n",
        "  files = os.listdir(path)\n",
        "  print(number)\n",
        "  for file in files:\n",
        "      img = np.asarray(cv.imread(path + file,0))\n",
        "\n",
        "#      threshold = 66\n",
        "#      ret,img = cv.threshold(img,threshold,255,cv.THRESH_TOZERO)\n",
        "#      threshold = 100\n",
        "#      ret,img = cv.threshold(img,threshold,255,cv.THRESH_BINARY)\n",
        "\n",
        "      X.append(img)\n",
        "      Y.append(number)\n",
        "\n",
        "np.random.seed(1)\n",
        "np.random.shuffle(X)\n",
        "np.random.seed(1)\n",
        "np.random.shuffle(Y)\n",
        "\n",
        "_x_train, _x_test, _y_train, _y_test =train_test_split(X, Y, test_size=0.33, random_state=111)\n",
        "\n",
        "x_train = np.array(_x_train)\n",
        "x_test = np.array(_x_test)\n",
        "y_train = np.array(_y_train)\n",
        "y_test = np.array(_y_test)\n",
        "\n",
        "idx = 704\n",
        "plt.imshow(x_train[idx])\n",
        "print(y_train[idx])\n",
        "\n",
        "#(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "XX=[]\n",
        "YY=[]\n",
        "\n",
        "for number in range (10):  \n",
        "  path = \"/var/test/\" + \"{:02d}\".format(number) + \"/\"\n",
        "  files = os.listdir(path)\n",
        "  del XX[:]\n",
        "  del YY[:]\n",
        "  for file in files:\n",
        "#      im2 = Image.open(path + file)\n",
        "      img = np.asarray(cv.imread(path + file,0))\n",
        "      threshold = 66\n",
        "      ret,img = cv.threshold(img,threshold,255,cv.THRESH_TOZERO)\n",
        "#      threshold = 100\n",
        "#      ret,img = cv.threshold(img,threshold,255,cv.THRESH_BINARY)\n",
        "      XX.append(img)\n",
        "      YY.append(number)\n",
        "\n",
        "np.random.seed(1)\n",
        "np.random.shuffle(XX)\n",
        "np.random.seed(1)\n",
        "np.random.shuffle(YY)\n",
        "\n",
        "#x_test = np.array(XX)\n",
        "#y_test = np.array(YY)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ve0-0z2HcSpv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-v6qXV3eTQv",
        "colab_type": "code",
        "outputId": "ec4fb217-7a18-4fe3-8a79-ac7a32b1eb0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "\n",
        "model=ResNet(img_rows,img_cols,img_channels, x_train)\n",
        "#model.compile(loss='categorical_crossentropy',\n",
        "#                  optimizer='adam',\n",
        "#                  metrics=['accuracy'])\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "\n",
        "model.save('/var/tmp/ac')\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (12614, 28, 28, 1)\n",
            "12614 train samples\n",
            "6213 test samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 12614 samples, validate on 6213 samples\n",
            "Epoch 1/12\n",
            "12614/12614 [==============================] - 49s 4ms/step - loss: 1.6678 - acc: 0.4397 - val_loss: 2.9529 - val_acc: 0.4882\n",
            "Epoch 2/12\n",
            "12614/12614 [==============================] - 35s 3ms/step - loss: 0.2573 - acc: 0.9282 - val_loss: 2.6054 - val_acc: 0.5762\n",
            "Epoch 3/12\n",
            "12614/12614 [==============================] - 35s 3ms/step - loss: 0.1168 - acc: 0.9664 - val_loss: 0.5577 - val_acc: 0.8904\n",
            "Epoch 4/12\n",
            "12614/12614 [==============================] - 35s 3ms/step - loss: 0.0500 - acc: 0.9880 - val_loss: 0.4624 - val_acc: 0.8915\n",
            "Epoch 5/12\n",
            "12614/12614 [==============================] - 35s 3ms/step - loss: 0.0466 - acc: 0.9876 - val_loss: 0.0590 - val_acc: 0.9808\n",
            "Epoch 6/12\n",
            "12614/12614 [==============================] - 35s 3ms/step - loss: 0.0552 - acc: 0.9893 - val_loss: 0.0430 - val_acc: 0.9871\n",
            "Epoch 7/12\n",
            "12614/12614 [==============================] - 35s 3ms/step - loss: 0.0040 - acc: 0.9993 - val_loss: 0.0501 - val_acc: 0.9911\n",
            "Epoch 8/12\n",
            "12614/12614 [==============================] - 35s 3ms/step - loss: 0.0099 - acc: 0.9978 - val_loss: 0.0063 - val_acc: 0.9982\n",
            "Epoch 9/12\n",
            "12614/12614 [==============================] - 35s 3ms/step - loss: 3.0168e-04 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 0.9995\n",
            "Epoch 10/12\n",
            "12614/12614 [==============================] - 35s 3ms/step - loss: 1.2081e-04 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 0.9997\n",
            "Epoch 11/12\n",
            "12614/12614 [==============================] - 35s 3ms/step - loss: 7.7041e-05 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 0.9997\n",
            "Epoch 12/12\n",
            "12614/12614 [==============================] - 35s 3ms/step - loss: 6.1265e-05 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 0.9997\n",
            "Test loss: 0.002000413935277539\n",
            "Test accuracy: 0.9996780943183647\n",
            "[0.002000413935277539, 0.9996780943183647]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPQDE6faWKgb",
        "colab_type": "code",
        "outputId": "42ab9694-0733-4684-ad66-228a39a52bba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        }
      },
      "source": [
        "#(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "XX=[]\n",
        "YY=[]\n",
        "\n",
        "for number in range (10):  \n",
        "  path = \"/var/test/\" + \"{:02d}\".format(number) + \"/\"\n",
        "  files = os.listdir(path)\n",
        "  del XX[:]\n",
        "  del YY[:]\n",
        "  for file in files:\n",
        "#      im2 = Image.open(path + file)\n",
        "      img = np.asarray(cv.imread(path + file,0))\n",
        "\n",
        "      threshold = 66\n",
        "      ret,img = cv.threshold(img,threshold,255,cv.THRESH_TOZERO)\n",
        "#      threshold = 100\n",
        "#      ret,img = cv.threshold(img,threshold,255,cv.THRESH_BINARY)\n",
        "      XX.append(img)\n",
        "      YY.append(number)\n",
        "\n",
        "\n",
        "  x_data = np.array(XX)\n",
        "  y_data = np.array(YY)\n",
        "  plt.imshow(x_data[0])\n",
        "  \n",
        "  if K.image_data_format() == 'channels_first':\n",
        "      x_data = x_data.reshape(x_data.shape[0], 1, img_rows, img_cols)\n",
        "  else:\n",
        "      x_data = x_data.reshape(x_data.shape[0], img_rows, img_cols, 1)\n",
        "\n",
        "  x_data = x_data.astype('float32')\n",
        "  x_data /= 255\n",
        "  y_data = keras.utils.to_categorical(y_data, num_classes)\n",
        "  score = model.evaluate(x_data, y_data, verbose=0)\n",
        "  print('Number :' +str(number))\n",
        "  print('Test loss:', score[0])\n",
        "  print('Test accuracy:', score[1])\n",
        "#  expect = model.predict_classes(x_data,batch_size=5)\n",
        "#  expect = model.predict(x_data,batch_size=5)\n",
        "#  expect = model.predict(x_data)\n",
        "#  print(expect)\n",
        "\n",
        "del XX[:]\n",
        "del YY[:]\n",
        "\n",
        "for number in range (10):  \n",
        "  path = \"/var/test/\" + \"{:02d}\".format(number) + \"/\"\n",
        "  files = os.listdir(path)\n",
        "  for file in files:\n",
        "      im2 = Image.open(path + file)\n",
        "      img = np.asarray(cv.imread(path + file,0))\n",
        "      threshold = 66\n",
        "      ret,img = cv.threshold(img,threshold,255,cv.THRESH_TOZERO)\n",
        "#      threshold = 100\n",
        "#      ret,img = cv.threshold(img,threshold,255,cv.THRESH_TOZERO)\n",
        "#      ret,img = cv.threshold(img,threshold,255,cv.THRESH_BINARY)\n",
        "      XX.append(img)\n",
        "      YY.append(number)\n",
        "\n",
        "np.random.seed(1)\n",
        "np.random.shuffle(XX)\n",
        "np.random.seed(1)\n",
        "np.random.shuffle(YY)\n",
        "\n",
        "x_data = np.array(XX)\n",
        "y_data = np.array(YY)\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_data = x_data.reshape(x_data.shape[0], 1, img_rows, img_cols)\n",
        "else:\n",
        "    x_data = x_data.reshape(x_data.shape[0], img_rows, img_cols, 1)\n",
        "\n",
        "x_data = x_data.astype('float32')\n",
        "x_data /= 255\n",
        "y_data = keras.utils.to_categorical(y_data, num_classes)\n",
        "score = model.evaluate(x_data, y_data, verbose=0)\n",
        "print('=== Total ====')\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number :0\n",
            "Test loss: 0.00014617960550822318\n",
            "Test accuracy: 1.0\n",
            "Number :1\n",
            "Test loss: 2.0984145521651953e-05\n",
            "Test accuracy: 1.0\n",
            "Number :2\n",
            "Test loss: 0.001144096371717751\n",
            "Test accuracy: 1.0\n",
            "Number :3\n",
            "Test loss: 0.18664388358592987\n",
            "Test accuracy: 0.9599999785423279\n",
            "Number :4\n",
            "Test loss: 0.0004607090959325433\n",
            "Test accuracy: 1.0\n",
            "Number :5\n",
            "Test loss: 1.6706131646060385e-05\n",
            "Test accuracy: 1.0\n",
            "Number :6\n",
            "Test loss: 0.5660263299942017\n",
            "Test accuracy: 0.8799999952316284\n",
            "Number :7\n",
            "Test loss: 0.0046902550384402275\n",
            "Test accuracy: 1.0\n",
            "Number :8\n",
            "Test loss: 0.0003873297537211329\n",
            "Test accuracy: 1.0\n",
            "Number :9\n",
            "Test loss: 1.1859017831739038e-05\n",
            "Test accuracy: 1.0\n",
            "=== Total ====\n",
            "Test loss: 0.07595480647147633\n",
            "Test accuracy: 0.984\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwkQls_uAbhE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}